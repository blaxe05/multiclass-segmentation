{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI NIH : Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data is supposed to be sharing the same orientation, resolution and matrix size (i.e. sharing a common header for the whole dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import json\n",
    "import math\n",
    "import numbers\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from msct_image import Image as msct_Image\n",
    "from PIL import Image as PIL_Image\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage.interpolation import map_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"alpha_range\": [\n",
      "        4, \n",
      "        6\n",
      "    ], \n",
      "    \"crop_size\": [\n",
      "        200, \n",
      "        150\n",
      "    ], \n",
      "    \"elastic_rate\": 0.5, \n",
      "    \"flip_rate\": 0.5, \n",
      "    \"max_angle\": 20, \n",
      "    \"ratio_range\": [\n",
      "        0.75, \n",
      "        1.25\n",
      "    ], \n",
      "    \"scale_range\": [\n",
      "        0.5, \n",
      "        1\n",
      "    ], \n",
      "    \"sigma_range\": [\n",
      "        10, \n",
      "        30\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "parameters = json.load(open('/Users/frpau_local/Documents/nih/data/luisa_with_gt/parameters.json'))\n",
    "print json.dumps(parameters, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticTransform(object):\n",
    "    def __init__(self, alpha_range, sigma_range, p=0.5):\n",
    "        self.alpha_range = alpha_range\n",
    "        self.sigma_range = sigma_range\n",
    "        self.p = p\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_params(alpha_range, sigma_range):\n",
    "        alpha = np.random.uniform(alpha_range[0], alpha_range[1])\n",
    "        sigma = np.random.uniform(sigma_range[0], sigma_range[1])\n",
    "        return alpha, sigma\n",
    "\n",
    "    @staticmethod\n",
    "    def elastic_transform(image, alpha, sigma):\n",
    "        shape = image.shape\n",
    "        dx = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "        dy = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "\n",
    "        x, y = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), indexing='ij')\n",
    "        indices = np.reshape(x+dx, (-1, 1)), np.reshape(y+dy, (-1, 1))\n",
    "        return map_coordinates(image, indices, order=1).reshape(shape)\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        if np.random.random() < self.p:\n",
    "            param_alpha, param_sigma = self.get_params(self.alpha_range, self.sigma_range)\n",
    "            \n",
    "            input_data = np.array(sample['input'])\n",
    "            input_data = self.elastic_transform(input_data, param_alpha, param_sigma)\n",
    "            input_data = PIL_Image.fromarray(input_data, mode='F')\n",
    "            \n",
    "            gt_data = sample['gt']\n",
    "            for i in range(len(gt_data)):\n",
    "                gt = np.array(gt_data[i])\n",
    "                gt = self.elastic_transform(gt, param_alpha, param_sigma)\n",
    "                gt[gt >= 0.5] = 1.0\n",
    "                gt[gt < 0.5] = 0.0\n",
    "                gt_data[i] = PIL_Image.fromarray(gt, mode='F')\n",
    "\n",
    "                \n",
    "            sample['input'] = input_data\n",
    "            sample['gt'] = gt_data\n",
    "            \n",
    "            for i in range(len(gt_data)) :\n",
    "                gt_data[i].save(\"gt_\"+str(i)+\"_elastic.tiff\")\n",
    "        \n",
    "        return sample\n",
    "\n",
    "class ToPIL(object):\n",
    "    def __call__(self, sample):\n",
    "        sample['input'] = PIL_Image.fromarray(np.array(sample['input']), mode='F')\n",
    "        sample['gt'] = [PIL_Image.fromarray(np.array(gt), mode='F') for gt in sample['gt']]\n",
    "        for i in range(len(sample['gt'])) :\n",
    "                sample['gt'][i].save(\"gt_\"+str(i)+\"_original.tiff\")\n",
    "        return sample\n",
    "    \n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        sample['input'] = torch.Tensor(np.array(sample['input']))\n",
    "        sample['gt'] = [torch.Tensor(np.array(gt)) for gt in sample['gt']]\n",
    "        return sample\n",
    "\n",
    "class RandomRotation(object):\n",
    "    def __init__(self, degrees, resample=False, expand=False, center=None):\n",
    "        if isinstance(degrees, numbers.Number):\n",
    "            if degrees < 0:\n",
    "                raise ValueError(\"If degrees is a single number, it must be positive.\")\n",
    "            self.degrees = (-degrees, degrees)\n",
    "        else:\n",
    "            if len(degrees) != 2:\n",
    "                raise ValueError(\"If degrees is a sequence, it must be of len 2.\")\n",
    "            self.degrees = degrees\n",
    "\n",
    "        self.resample = resample\n",
    "        self.expand = expand\n",
    "        self.center = center\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params(degrees):\n",
    "        angle = np.random.uniform(degrees[0], degrees[1])\n",
    "        return angle\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        angle = self.get_params(self.degrees)\n",
    "        rdict = {}\n",
    "        \n",
    "        input_data = sample['input']\n",
    "        input_data = F.rotate(input_data, angle, self.resample, self.expand, self.center)\n",
    "        rdict['input'] = input_data\n",
    "        \n",
    "        gt_data = sample['gt']\n",
    "        gt_data = [F.rotate(gt, angle, self.resample, self.expand, self.center) for gt in gt_data]\n",
    "        rdict['gt'] = gt_data\n",
    "        \n",
    "        for i in range(len(gt_data)) :\n",
    "            gt_data[i].save(\"gt_\"+str(i)+\"_rotation.tiff\")\n",
    "            \n",
    "        return rdict\n",
    "    \n",
    "\n",
    "class RandomResizedCrop(object):\n",
    "    \"\"\"Crop the given PIL Image to random size and aspect ratio.\n",
    "    A crop of random size (default: of 0.08 to 1.0) of the original size and a random aspect ratio (default: of 3/4 to 4/3) of the original aspect ratio is made. This crop is finally resized to given size.\n",
    "    Args:\n",
    "        size: expected output size of each edge\n",
    "        scale: range of size of the origin size cropped\n",
    "        ratio: range of aspect ratio of the origin aspect ratio cropped\n",
    "        interpolation: Default: PIL.Image.BILINEAR\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, scale=(0.08, 1.0), ratio=(3. / 4., 4. / 3.), interpolation=PIL_Image.BILINEAR):\n",
    "        self.size = (size[0], size[1])\n",
    "        self.interpolation = interpolation\n",
    "        self.scale = scale\n",
    "        self.ratio = ratio\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params(img, scale, ratio):\n",
    "        \"\"\"Get parameters for ``crop`` for a random sized crop.\n",
    "        Args:\n",
    "            img (PIL Image): Image to be cropped.\n",
    "            scale (tuple): range of size of the origin size cropped\n",
    "            ratio (tuple): range of aspect ratio of the origin aspect ratio cropped\n",
    "        Returns:\n",
    "            tuple: params (i, j, h, w) to be passed to ``crop`` for a random\n",
    "                sized crop.\n",
    "        \"\"\"\n",
    "        for attempt in range(10):\n",
    "            area = img.size[0] * img.size[1]\n",
    "            target_area = random.uniform(*scale) * area\n",
    "            aspect_ratio = random.uniform(*ratio)\n",
    "\n",
    "            w = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "            h = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "            if random.random() < 0.5:\n",
    "                w, h = h, w\n",
    "\n",
    "            if w <= img.size[0] and h <= img.size[1]:\n",
    "                i = random.randint(0, img.size[1] - h)\n",
    "                j = random.randint(0, img.size[0] - w)\n",
    "                return i, j, h, w\n",
    "\n",
    "        # Fallback\n",
    "        w = min(img.size[0], img.size[1])\n",
    "        i = (img.size[1] - w) // 2\n",
    "        j = (img.size[0] - w) // 2\n",
    "        return i, j, w, w\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        i, j, h, w = self.get_params(sample['input'], self.scale, self.ratio)\n",
    "        rdict = {}\n",
    "        \n",
    "        input_data = F.resized_crop(sample['input'], i, j, h, w, self.size, self.interpolation)\n",
    "        \n",
    "        gt_data = [F.resized_crop(gt, i, j, h, w, self.size, self.interpolation) for gt in sample['gt']]\n",
    "        for i in range(len(gt_data)):\n",
    "            gt = np.array(gt_data[i])\n",
    "            gt[gt >= 0.5] = 1.0\n",
    "            gt[gt < 0.5] = 0.0\n",
    "            gt_data[i] = PIL_Image.fromarray(gt, mode='F')\n",
    "\n",
    "        rdict['input'] = input_data\n",
    "        rdict['gt'] = gt_data\n",
    "\n",
    "        for i in range(len(gt_data)) :\n",
    "            gt_data[i].save(\"gt_\"+str(i)+\"_resize.tiff\")\n",
    "        \n",
    "        return rdict\n",
    "    \n",
    "    \n",
    "class RandomVerticalFlip(object):\n",
    "    \"\"\"Vertically flip the given PIL Image randomly with a given probability.\n",
    "    Args:\n",
    "        p (float): probability of the image being flipped. Default value is 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        if random.random() < self.p:\n",
    "            sample['input'] = F.vflip(sample['input'])\n",
    "            sample['gt'] = [F.vflip(gt) for gt in sample['gt']]\n",
    "        return sample\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "toTensor = ToTensor()\n",
    "toPIL = ToPIL()\n",
    "randomVFlip = RandomVerticalFlip()\n",
    "randomResizedCrop = RandomResizedCrop(parameters[\"crop_size\"], scale=parameters[\"scale_range\"], ratio=parameters[\"ratio_range\"])\n",
    "randomRotation = RandomRotation(parameters[\"max_angle\"])\n",
    "elasticTransform = ElasticTransform(parameters[\"alpha_range\"], parameters[\"sigma_range\"], parameters[\"elastic_rate\"])\n",
    "\n",
    "composed = transforms.Compose([toPIL,randomVFlip,randomRotation,randomResizedCrop, elasticTransform, toTensor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRI2DSegDataset(Dataset):\n",
    "    \"\"\"This is a generic class for 2D (slice-wise) segmentation datasets.\n",
    "    \n",
    "    :param txt_path_file: the path to a txt file containing the list of paths to input data files and gt masks.\n",
    "    :param slice_axis: axis to make the slicing (default axial).\n",
    "    :param cache: if the data should be cached in memory or not.\n",
    "    :param transform: transformations to apply.\n",
    "    \"\"\"\n",
    "    def __init__(self, txt_path_file, slice_axis=2, cache=True, transform=None):\n",
    "        self.filenames = []\n",
    "        self.header = {}\n",
    "        self.class_names = []\n",
    "        self.read_filenames(txt_path_file)\n",
    "        self.transform = transform\n",
    "        self.cache = cache\n",
    "        self.slice_axis = slice_axis\n",
    "        self.handlers = []\n",
    "        \n",
    "        self._load_files()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.handlers)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.handlers[index]\n",
    "        data_dict = {\n",
    "            'input': sample[0],\n",
    "            'gt': [sample[i] for i in range(1, len(sample))]\n",
    "        }\n",
    "        \n",
    "        if self.transform:\n",
    "            data_dict = self.transform(data_dict)## TODO : apply same tranform to input and gt\n",
    "            \n",
    "        return data_dict\n",
    "        \n",
    "    \n",
    "    def _load_files(self):\n",
    "        for input_filename, gt_dict in self.filenames:\n",
    "            input_3D = msct_Image(input_filename)\n",
    "            if self.slice_axis == 0:\n",
    "                resolution = list(np.around(input_3D.dim[5:7], 2))\n",
    "                matrix_size = input_3D.dim[1:3]\n",
    "            elif self.slice_axis == 1:\n",
    "                resolution = list(np.around([input_3D.dim[4], input_3D.dim[6]], 2))\n",
    "                matrix_size = (input_3D.dim[0], input_3D.dim[2])\n",
    "            else:\n",
    "                if self.slice_axis != 2:\n",
    "                    print \"Invalid slice axis given, replaced by default value of 2.\"\n",
    "                    self.slice_axis = 2\n",
    "                resolution = list(np.around(input_3D.dim[4:6], 2))\n",
    "                matrix_size = input_3D.dim[0:2]\n",
    "                \n",
    "            input_header = {\"orientation\":input_3D.orientation, \"resolution\":resolution, \"matrix_size\":matrix_size}\n",
    "            \n",
    "            gt_3D = []\n",
    "            gt_class_names = sorted(gt_dict.keys())\n",
    "            for gt_class in gt_class_names:\n",
    "                gt_3D.append(msct_Image(gt_dict[gt_class]))\n",
    "                  \n",
    "            if not self.header:\n",
    "                self.header = input_header\n",
    "            #sanity check for consistent header\n",
    "            elif self.header != input_header :\n",
    "                print self.header\n",
    "                print input_header\n",
    "                raise RuntimeError('Inconsistent header in input files.')\n",
    "                \n",
    "            if not self.class_names:\n",
    "                self.class_names = gt_class_names \n",
    "            #sanity check for consistent gt classes\n",
    "            elif self.class_names != gt_class_names:\n",
    "                raise RuntimeError('Inconsistent classes in gt files.')\n",
    "                \n",
    "            for i in range(input_3D.dim[2]):\n",
    "                if self.slice_axis == 0:\n",
    "                    input_slice = input_3D.data[i,::,::]\n",
    "                    gt_slices = [gt.data[i,::,::] for gt in gt_3D]\n",
    "                elif self.slice_axis == 1:\n",
    "                    input_slice = input_3D.data[::,i,::]\n",
    "                    gt_slices = [gt.data[::,i,::] for gt in gt_3D]\n",
    "                else:\n",
    "                    input_slice = input_3D.data[::,::,i]\n",
    "                    gt_slices = [gt.data[::,::,i] for gt in gt_3D]\n",
    "                seg_item = [input_slice]\n",
    "                for gt_slice in gt_slices:\n",
    "                    if gt_slice.shape != input_slice.shape:\n",
    "                        print \"input dimensions : {}\".format(input_slice.shape)\n",
    "                        print \"gt dimensions : {}\".format(gt_slice.shape)\n",
    "                        raise RuntimeError('Input and ground truth with different dimensions.')\n",
    "                    seg_item.append(gt_slice)\n",
    "                self.handlers.append(np.array(seg_item))\n",
    "                \n",
    "    \n",
    "    def read_filenames(self, txt_path_file):\n",
    "        for line in open(txt_path_file, 'r'):\n",
    "            if \"input\" in line:\n",
    "                fnames=[None, {}]\n",
    "                line = line.split()\n",
    "                if len(line)%2:\n",
    "                    raise RuntimeError('Error in filenames txt file parsing.')\n",
    "                for i in range(len(line)/2):\n",
    "                    try:\n",
    "                        msct_Image(line[2*i+1])\n",
    "                    except Exception:\n",
    "                        raise RuntimeError(\"Invalid path in filenames txt file.\")\n",
    "                    if(line[2*i]==\"input\"):\n",
    "                        fnames[0]=line[2*i+1]\n",
    "                    else:\n",
    "                        fnames[1][line[2*i]]=line[2*i+1]\n",
    "                self.filenames.append((fnames[0], fnames[1]))\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MRI2DSegDataset(\"/Users/frpau_local/Documents/nih/data/luisa_with_gt/filenames_csf_gm_nawm.txt\", transform = composed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gt': [\n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     0\n",
       "         ...          ⋱          ...       \n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     0\n",
       "  [torch.FloatTensor of size 200x150], \n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     0\n",
       "         ...          ⋱          ...       \n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     0\n",
       "  [torch.FloatTensor of size 200x150], \n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     0\n",
       "         ...          ⋱          ...       \n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     0\n",
       "  [torch.FloatTensor of size 200x150]], 'input': \n",
       "    311.5126    378.7030    414.1377  ...    4989.1919   5337.6646   5545.5952\n",
       "    535.4362    408.4663    360.9075  ...    5144.7070   5473.3569   5299.9590\n",
       "    534.9650    464.1174    454.6202  ...    5440.7754   5333.5718   5096.0771\n",
       "                 ...                   ⋱                   ...                \n",
       "      0.0000      0.0000      0.0000  ...       0.0000      0.0000      0.0000\n",
       "      0.0000      0.0000      0.0000  ...       0.0000      0.0000      0.0000\n",
       "      0.0000      0.0000      0.0000  ...       0.0000      0.0000      0.0000\n",
       " [torch.FloatTensor of size 200x150]}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
