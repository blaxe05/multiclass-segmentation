{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI NIH : UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To vizualize on tensor board :\n",
    "\n",
    "tensorboard --logdir < path to runs directory >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '../')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1' # number of the GPU to use if cuda is enabled\n",
    "from dataset import *\n",
    "import transforms\n",
    "import json\n",
    "from torchvision import transforms as torch_transforms\n",
    "import torchvision.utils as vutils\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from models import UNet\n",
    "import losses\n",
    "from metrics import *\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_parameters = '/Users/frpau_local/Documents/nih/data/luisa_with_gt/parameters.json'\n",
    "path_filenames_training = \"/Users/frpau_local/Documents/nih/data/luisa_with_gt/filenames_training.txt\"\n",
    "path_filenames_validation = \"/Users/frpau_local/Documents/nih/data/luisa_with_gt/filenames_validation.txt\"\n",
    "path_runs = \"/Users/frpau_local/Documents/nih/code/runs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print \"working on {}\".format(device)\n",
    "if torch.cuda.is_available():\n",
    "    print \"using GPU number {}\".format(gpu_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"training\": {\n",
      "        \"poly_schedule_p\": 0.9, \n",
      "        \"optimizer\": \"adam\", \n",
      "        \"write_param_histograms\": false, \n",
      "        \"learning_rate\": 1e-06, \n",
      "        \"batch_size\": 10, \n",
      "        \"loss_function\": \"dice\", \n",
      "        \"lr_schedule\": \"poly\", \n",
      "        \"nb_epochs\": 10\n",
      "    }, \n",
      "    \"transforms\": {\n",
      "        \"flip_rate\": 0.5, \n",
      "        \"ratio_range\": [\n",
      "            0.75, \n",
      "            1.25\n",
      "        ], \n",
      "        \"elastic_rate\": 0.3, \n",
      "        \"sigma_range\": [\n",
      "            3.5, \n",
      "            4\n",
      "        ], \n",
      "        \"alpha_range\": [\n",
      "            10, \n",
      "            15\n",
      "        ], \n",
      "        \"crop_size\": [\n",
      "            224, \n",
      "            128\n",
      "        ], \n",
      "        \"max_angle\": 20, \n",
      "        \"scale_range\": [\n",
      "            0.5, \n",
      "            1\n",
      "        ]\n",
      "    }, \n",
      "    \"net\": {\n",
      "        \"drop_rate\": 0.3, \n",
      "        \"bn_momentum\": 0.1\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "parameters = json.load(open(path_parameters))\n",
    "print json.dumps(parameters, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining transormations\n",
    "toTensor = transforms.ToTensor()\n",
    "toPIL = transforms.ToPIL()\n",
    "randomVFlip = transforms.RandomVerticalFlip()\n",
    "randomResizedCrop = transforms.RandomResizedCrop(parameters[\"transforms\"][\"crop_size\"], scale=parameters[\"transforms\"][\"scale_range\"], ratio=parameters[\"transforms\"][\"ratio_range\"])\n",
    "randomRotation = transforms.RandomRotation(parameters[\"transforms\"][\"max_angle\"])\n",
    "elasticTransform = transforms.ElasticTransform(parameters[\"transforms\"][\"alpha_range\"], parameters[\"transforms\"][\"sigma_range\"], parameters[\"transforms\"][\"elastic_rate\"])\n",
    "centerCrop = transforms.CenterCrop2D(parameters[\"transforms\"][\"crop_size\"])\n",
    "\n",
    "# creating composed transformation\n",
    "# Composed transformations should always contain toPIL as first transformations (since other transforamtions are made to work on PIL images) and toTensor as last transforamtion (since the network is excpecting tensors as input). \n",
    "composed = torch_transforms.Compose([toPIL,randomVFlip,randomRotation,randomResizedCrop, elasticTransform, toTensor])\n",
    "crop_val = torch_transforms.Compose([toPIL, centerCrop, toTensor])\n",
    "\n",
    "# creating datasets\n",
    "# Datasets should be created with at least a toTensor transformation or a composed transformation with toTensor as last transformation since the network is excpecting tensors as input.\n",
    "training_dataset = MRI2DSegDataset(path_filenames_training, transform = composed)\n",
    "validation_dataset = MRI2DSegDataset(path_filenames_validation, transform = crop_val)\n",
    "\n",
    "# creating data loaders\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=parameters[\"training\"][\"batch_size\"], shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=parameters[\"training\"][\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownConv(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, drop_rate=0.4, bn_momentum=0.1):\n",
    "        super(DownConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_feat, out_feat, kernel_size=3, padding=1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(out_feat, momentum=bn_momentum)\n",
    "        self.conv1_drop = nn.Dropout2d(drop_rate)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_feat, out_feat, kernel_size=3, padding=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(out_feat, momentum=bn_momentum)\n",
    "        self.conv2_drop = nn.Dropout2d(drop_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.conv1_bn(x)\n",
    "        x = self.conv1_drop(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv2_bn(x)\n",
    "        x = self.conv2_drop(x)        \n",
    "        return x\n",
    "    \n",
    "class UpConv(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, drop_rate=0.4, bn_momentum=0.1):\n",
    "        super(UpConv, self).__init__()\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.downconv = DownConv(in_feat, out_feat, drop_rate, bn_momentum)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = self.up1(x)\n",
    "        x = torch.cat([x, y], dim=1)\n",
    "        x = self.downconv(x)\n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, drop_rate=0.4, bn_momentum=0.1):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        #Downsampling path\n",
    "        self.conv1 = DownConv(1, 64, drop_rate, bn_momentum)\n",
    "        self.mp1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv2 = DownConv(64, 128, drop_rate, bn_momentum)\n",
    "        self.mp2 = nn.MaxPool2d(2)    \n",
    "\n",
    "        self.conv3 = DownConv(128, 256, drop_rate, bn_momentum)\n",
    "        self.mp3 = nn.MaxPool2d(2)          \n",
    "\n",
    "        # Bottom\n",
    "        self.conv4 = DownConv(256, 256, drop_rate, bn_momentum)\n",
    "\n",
    "        # Upsampling path\n",
    "        self.up1 = UpConv(512, 256, drop_rate, bn_momentum)\n",
    "        self.up2 = UpConv(384, 128, drop_rate, bn_momentum)\n",
    "        self.up3 = UpConv(192, 64, drop_rate, bn_momentum)\n",
    "\n",
    "        self.conv9 = nn.Conv2d(64, 4, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.mp1(x1)\n",
    "\n",
    "        x3 = self.conv2(x2)\n",
    "        x4 = self.mp2(x3)\n",
    "        \n",
    "        x5 = self.conv3(x4)\n",
    "        x6 = self.mp3(x5)    \n",
    "        \n",
    "        # Bottom\n",
    "        x7 = self.conv4(x6)\n",
    "        \n",
    "        # Up-sampling\n",
    "        x8 = self.up1(x7, x5)\n",
    "        x9 = self.up2(x8, x3)\n",
    "        x10 = self.up3(x9, x1)\n",
    "        \n",
    "        x11 = self.conv9(x10)\n",
    "        preds = F.sigmoid(x11)        \n",
    "        \n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bg_gt(gts):\n",
    "    gt_size = gts[0].size()\n",
    "    bg_gt = torch.ones([gt_size[0],1,gt_size[2], gt_size[3]])\n",
    "    zeros = torch.zeros([gt_size[0],1,gt_size[2], gt_size[3]])\n",
    "    for gt in gts:\n",
    "        bg_gt = torch.max(bg_gt - gt, zeros)\n",
    "    return bg_gt\n",
    "\n",
    "def dice_loss(pred, gts):\n",
    "    eps = 0.0000000001\n",
    "    loss = 1.\n",
    "    intersections = []\n",
    "    unions = []\n",
    "    weights = []\n",
    "\n",
    "    for i in range(len(gts)):\n",
    "        weights.append(1/(torch.sum(gts[i]))**2+eps)\n",
    "        intersections.append((pred[::,i,::,::].data.contiguous().view(-1)*gts[i].view(-1)).sum())\n",
    "        unions.append(torch.sum(pred[::,i,::,::])+torch.sum(gts[i]))\n",
    "\n",
    "    loss = loss-2*sum([w*i for w,i in zip(weights, intersections)])/(sum([w*u for w,u in zip(weights, unions)])+eps)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_score(pred, gts):\n",
    "    \"\"\"Computation of statistical numerical scores:\n",
    "\n",
    "    * FP = False Positives\n",
    "    * FN = False Negatives\n",
    "    * TP = True Positives\n",
    "    * TN = True Negatives\n",
    "\n",
    "    return: tuple (FP, FN, TP, TN)\n",
    "    \"\"\"\n",
    "    np_pred = pred.numpy()\n",
    "    np_gts = [get_bg_gt(gts)]+gts\n",
    "    np_gts = [gt.numpy() for gt in np_gts]\n",
    "    FP = []\n",
    "    FN = []\n",
    "    TP = []\n",
    "    TN = []\n",
    "    for i in range(len(np_gts)):\n",
    "        FP.append(np.float(np.sum((np_pred == i) & (np_gts[i] == 0))))\n",
    "        FN.append(np.float(np.sum((np_pred != i) & (np_gts[i] == 1))))\n",
    "        TP.append(np.float(np.sum((np_pred == i) & (np_gts[i] == 1))))\n",
    "        TN.append(np.float(np.sum((np_pred != i) & (np_gts[i] == 0))))\n",
    "    return FP, FN, TP, TN\n",
    "\n",
    "\n",
    "def precision_score(FP, FN, TP, TN):\n",
    "    # PPV\n",
    "    precision = []\n",
    "    for i in range(len(FP)):\n",
    "        if (TP[i] + FP[i]) <= 0.0:\n",
    "            precision.append(0.0)\n",
    "        else:\n",
    "            precision.append(np.divide(TP[i], TP[i] + FP[i])* 100.0)\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall_score(FP, FN, TP, TN):\n",
    "    # TPR, sensitivity\n",
    "    TPR = []\n",
    "    for i in range(len(FP)):\n",
    "        if (TP[i] + FN[i]) <= 0.0:\n",
    "            TPR.append(0.0)\n",
    "        else:\n",
    "            TPR.append(np.divide(TP[i], TP[i] + FN[i]) * 100.0)\n",
    "    return TPR\n",
    "\n",
    "\n",
    "def specificity_score(FP, FN, TP, TN):\n",
    "    TNR = []\n",
    "    for i in range(len(FP)):\n",
    "        if (TN[i] + FP[i]) <= 0.0:\n",
    "            TNR.append(0.0)\n",
    "        else:\n",
    "            TNR.append(np.divide(TN[i], TN[i] + FP[i]) * 100.0)\n",
    "    return TNR \n",
    "\n",
    "\n",
    "def intersection_over_union(FP, FN, TP, TN):\n",
    "    IOU = []\n",
    "    for i in range(len(FP)):\n",
    "        if (TP[i] + FP[i] + FN[i]) <= 0.0:\n",
    "            IOU.append(0.0)\n",
    "        else:\n",
    "            IOU.append(TP[i] / (TP[i] + FP[i] + FN[i]) * 100.0)\n",
    "    return IOU\n",
    "\n",
    "\n",
    "def accuracy_score(FP, FN, TP, TN):\n",
    "    accuracy = []\n",
    "    for i in range(len(FP)):\n",
    "        N = FP[i] + FN[i] + TP[i] + TN[i]\n",
    "        accuracy.append(np.divide(TP[i] + TN[i], N) * 100.0)\n",
    "    return accuracy\n",
    "\n",
    "def write_metrics(writer, predictions, gts, loss, epoch, tag):\n",
    "    \"\"\"\n",
    "    Write scalar metrics to tensorboard\n",
    "\n",
    "    :param writer: SummaryWriter object to write on\n",
    "    :param predictions: tensor containing predictions\n",
    "    :param gts: array of tensors containing ground truth\n",
    "    :param loss: tensor containing the loss value\n",
    "    :param epoch: int, number of the iteration\n",
    "    :param tag: string to specify which dataset is used (e.g. \"training\" or \"validation\")\n",
    "    \"\"\"\n",
    "    FP, FN, TP, TN = numeric_score(predictions, gts)\n",
    "    precision = precision_score(FP, FN, TP, TN)\n",
    "    recall = recall_score(FP, FN, TP, TN)\n",
    "    specificity = specificity_score(FP, FN, TP, TN)\n",
    "    iou = intersection_over_union(FP, FN, TP, TN)\n",
    "    accuracy = accuracy_score(FP, FN, TP, TN)\n",
    "\n",
    "    writer.add_scalar(\"loss_\"+tag, loss, epoch)\n",
    "    for i in range(len(precision)):\n",
    "        writer.add_scalar(\"precision_\"+str(i)+\"_\"+tag, precision[i], epoch)\n",
    "        writer.add_scalar(\"recall_\"+str(i)+\"_\"+tag, recall[i], epoch)\n",
    "        writer.add_scalar(\"specificity_\"+str(i)+\"_\"+tag, specificity[i], epoch)\n",
    "        writer.add_scalar(\"intersection_over_union_\"+str(i)+\"_\"+tag, iou[i], epoch)\n",
    "        writer.add_scalar(\"accuracy_\"+str(i)+\"_\"+tag, accuracy[i], epoch)\n",
    "\n",
    "\n",
    "def write_images(writer, input, output, predictions, gts, epoch, tag):\n",
    "    \"\"\"\n",
    "    Write images to tensorboard\n",
    "\n",
    "    :param writer: SummaryWriter object to write on\n",
    "    :param input: tensor containing input values\n",
    "    :param output: tensor containing output values\n",
    "    :param predictions: tensor containing predictions\n",
    "    :param gts: array of tensors containing ground truth\n",
    "    :param epoch: int, number of the iteration\n",
    "    :param tag: string to specify which dataset is used (e.g. \"training\" or \"validation\")\n",
    "    \"\"\"\n",
    "    input_max = max(torch.max(input), 0.00000001)\n",
    "    input_image = vutils.make_grid(input/input_max, normalize=True)\n",
    "    writer.add_image('Input '+tag, input_image, epoch)\n",
    "    for i in range(len(gts)):\n",
    "        output_image = vutils.make_grid(output[i,::,::], normalize=True)\n",
    "        writer.add_image('Output class '+str(i)+' '+tag, output_image, epoch)\n",
    "        pred_image = vutils.make_grid(predictions==i, normalize=False)\n",
    "        writer.add_image('Prediction class '+str(i)+' '+tag, pred_image, epoch)\n",
    "        gt_image = vutils.make_grid(gts[i], normalize=True)\n",
    "        writer.add_image('GT class '+str(i)+' '+tag, gt_image, epoch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet(drop_rate=parameters[\"net\"][\"drop_rate\"], bn_momentum=parameters[\"net\"][\"bn_momentum\"])\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss, optimizer and lr schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parameters[\"training\"][\"optimizer\"]==\"sgd\":\n",
    "    optimizer = optim.SGD(net.parameters(), lr=parameters[\"training\"]['learning_rate'], momentum=parameters[\"training\"]['sgd_momentum'])\n",
    "elif parameters[\"training\"][\"optimizer\"]==\"adam\":\n",
    "    optimizer = optim.Adam(net.parameters(), lr=parameters[\"training\"]['learning_rate'])\n",
    "    \n",
    "if parameters[\"training\"][\"loss_function\"]==\"dice\":\n",
    "    loss_function = dice_loss\n",
    "    \n",
    "if parameters[\"training\"][\"lr_schedule\"]==\"cosine\":\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, parameters[\"training\"][\"nb_epochs\"])\n",
    "elif parameters[\"training\"][\"lr_schedule\"]==\"poly\":\n",
    "    if not \"poly_schedule_p\" in parameters[\"training\"]:\n",
    "        parameters[\"training\"]['poly_schedule_p']=0.9\n",
    "    lr_lambda = lambda epoch: (1-epoch/parameters[\"training\"][\"nb_epochs\"])**parameters[\"training\"][\"poly_schedule_p\"]\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ccfded596e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mgts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_bg_gt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_batched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msample_batched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# make an array of ground truths (with the computed background gt mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/frpau_local/sct_3.1.1/python/lib/python2.7/site-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/frpau_local/sct_3.1.1/python/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "current_time = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "writer = SummaryWriter(log_dir=os.path.join(path_runs, current_time))\n",
    "writer.add_text(\"hyperparameters\", json.dumps(parameters)) # add hyperparameters to description\n",
    "last_run_dir = os.listdir(path_runs)[-1] # get the name of the directory of the current run (to save the model in that directory)\n",
    "\n",
    "best_loss = 0.\n",
    "batch_length = len(training_dataloader)\n",
    "\n",
    "for epoch in tqdm(range(parameters[\"training\"][\"nb_epochs\"])):\n",
    "    \n",
    "    loss_sum = 0.\n",
    "    scheduler.step()\n",
    "    net.train()\n",
    "    \n",
    "    writer.add_scalar(\"learning_rate\", scheduler.get_lr()[0], epoch)\n",
    "    \n",
    "    for i_batch, sample_batched in enumerate(training_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        input = sample_batched['input'].to(device)\n",
    "        output =  net(input)\n",
    "        gts = [get_bg_gt(sample_batched['gt'])]+sample_batched['gt'] # make an array of ground truths (with the computed background gt mask)\n",
    "        loss = loss_function(output, [gt.to(device) for gt in gts])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()/batch_length\n",
    "    \n",
    "    predictions = torch.argmax(output, 1, keepdim=True).to(\"cpu\") # get predicted class for each pixel (on cpu to compute metrics)\n",
    "        \n",
    "    # metrics\n",
    "    write_metrics(writer, predictions, gts, loss_sum, epoch, \"training\")\n",
    "\n",
    "    # images\n",
    "    input_for_image = sample_batched['input'][0]\n",
    "    output_for_image = output[0,::,::,::]\n",
    "    pred_for_image = predictions[0,0,::,::]\n",
    "    gts_for_image = [gt[0,::,::] for gt in gts]\n",
    "\n",
    "    write_images(writer, input_for_image, output_for_image, pred_for_image, gts_for_image, epoch, \"training\")\n",
    "\n",
    "    if \"write_param_histograms\" in parameters[\"training\"].keys() and parameters[\"training\"][\"write_param_histograms\"]:\n",
    "        # write net parameters histograms (make the training significantly slower)\n",
    "        for name, param in net.named_parameters():\n",
    "            writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
    "    \n",
    "    ## Validation ##  \n",
    "\n",
    "    loss_sum = 0.\n",
    "    net.eval()\n",
    "\n",
    "    for i_batch, sample_batched in enumerate(validation_dataloader):\n",
    "        output =  net(sample_batched['input'].to(device))\n",
    "        gts = [get_bg_gt(sample_batched['gt'])]+sample_batched['gt']\n",
    "        loss = loss_function(output, [gt.to(device) for gt in gts])\n",
    "        loss_sum += loss.item()/len(validation_dataloader)\n",
    "\n",
    "    predictions = torch.argmax(output, 1, keepdim=True).to(\"cpu\")\n",
    "\n",
    "\n",
    "    if loss_sum < best_loss:\n",
    "        torch.save(net, path_runs+\"/\"+last_run_dir+\"/best_model.pt\")\n",
    "\n",
    "    # metrics\n",
    "    write_metrics(writer, predictions, gts, loss_sum, epoch, \"validation\")\n",
    "\n",
    "    #images\n",
    "    input_for_image = sample_batched['input'][0]\n",
    "    output_for_image = output[0,::,::,::]\n",
    "    pred_for_image = predictions[0,0,::,::]\n",
    "    gts_for_image = [gt[0,::,::] for gt in gts]\n",
    "\n",
    "    write_images(writer, input_for_image, output_for_image, pred_for_image, gts_for_image, epoch, \"validation\")\n",
    "\n",
    "                \n",
    "writer.export_scalars_to_json(path_runs+\"/\"+last_run_dir+\"/all_scalars.json\")\n",
    "writer.close()\n",
    "\n",
    "torch.save(net, path_runs+\"/\"+last_run_dir+\"/final_model.pt\")\n",
    "\n",
    "print \"training complete, model saved at \"+path_runs+\"/\"+last_run_dir+\"/final_model.pt\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
